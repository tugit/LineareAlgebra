\section{Das charakteristische Polynom}
\subsection{Definition}\index{Eigenwert,-vektor,-raum}
\begin{Definition}[Eigenwert,Eigenvektor,Eigenraum]
	Seien $ V $ ein $ K $-VR und $ f\in\End(V) $. Dann heißen
		\begin{enumerate}[(i)]
			\item $ x\in K $ ein \emph{Eigenwert} von $ f $, falls  $ \exists v\in V^\times: f(v)=vx; $
			\item $ v\in V^\times $ ein \emph{Eigenvektor} von $ f $, falls  $\exists x\in K:f(v)=vx; $
			\item $ \ker(f-\id_Vx) \subset V $ ein \emph{Eigenraum}, falls $\ker(f-\id_Vx) \neq \{0\}.$
		\end{enumerate}
	\end{Definition}
\paragraph{Bemerkung}
	Der Skalar $ x\in K $ ist genau dann ein Eigenwert von $ f\in \End(V) $, wenn $ \ker(f-\id_Vx)\neq \{0\} $, d.h., wenn ein Eigenvektor $ v\in V^\times $ zu $ x $ existiert.
\paragraph{Beispiel}
	Für $ \frac{d}{ds} \in \End(C^\infty(\R))$ ist jedes $ x\in \R $ ein Eigenwert, da
		\[ \Big(\frac{d}{ds}-\id_Vx\Big)v = 0 \text{ für } v:\R\to\R,\ s\mapsto v(s):= e^{xs}, \]
	wobei $ v\in C^\infty(\R)\setminus \{0\} $, d.h. $ s\mapsto v(s)=e^{xs} $ ist ein Eigenvektor zum Eigenwert $ x\in\R $.
\paragraph{Beispiel}
	Ist $ \dim V < \infty $, so kann die Determinante zur Bestimmung von Eigenwerten von Endomorphismen $ f\in\End(V) $ benutzt werden, da
		\[ \ker(f-\id_Vx)\neq \{0\} \Leftrightarrow (f-\id_Vx) \text{ nicht injektiv}\Leftrightarrow \det(f-\id_Vx) = 0, \]
	d.h. das Auffinden von Eigenwerten $ x\in K $ von $ f $ ist reduziert auf die Bestimmung der Nullstellen der Funktion
		\[ K\ni x\mapsto \det(f-\id_Vx)\in K. \]
		
\paragraph{Beispiel}	
	Ist z.B. $ (b_1,b_2) $ Basis von $ V $ und $ f\in \End(V) $ durch $ f(B)=BX $ gegeben, so liefern die Nullstellen der Polynomfunktion
		\begin{gather*}
		\det(f-\id_Vx) = \det(X-E_2 x)= \det \begin{pmatrix}
		x_{11}-x & x_{12}\\
		x_{21} & x_{22} -x
		\end{pmatrix}\\
	= (x_{11}-x)(x_{22}-x)-x_{12}x_{21}
	= x^2 - x(x_{11}+x_{22}) + (x_{11}x_{22}-x_{12}x_{21})
		\end{gather*}
	die Eigenwerte von $ f $ -- beispielsweise erhalten wir für
		\[ X = \begin{pmatrix} 2 &3\\1 & 0 \end{pmatrix}:\ 
			\det(f-\id_Vx) = x^2-2x-3 = (x+1)(x-3), \]
	also Eigenwerte $ x_1 = -1 $ und $ x_2 = 3 $ mit zugehörigen Eigenvektoren als Lösungen von
		\[ v_i \in \ker(f-\id_Vx_i), \]
	also durch Lösungen der linearen Gleichungssysteme % Die Rechtsmultiplikation der Koeffizienten der Linearkombination in der entsprechenden Basis ergeben die Koeffizenten des Bild des Vektors. Gesucht sind nun eben jene Koeffizenten, bei denen die Bildkoeffizienten alle 0 sind.
		\[ \begin{pmatrix}
		2-(-1) & 3\\ 1 & -(-1)
		\end{pmatrix}
		\begin{pmatrix}
		v_1^1\\v_1^2
		\end{pmatrix} = \begin{pmatrix}
		3 & 3\\ 1 & 1
		\end{pmatrix}
		\begin{pmatrix}
		v_1^1\\v_1^2
		\end{pmatrix} \text{ und} \]
		\[ \begin{pmatrix}
		2-3 & 3\\ 1 & -3
		\end{pmatrix}
		\begin{pmatrix}
		v_2^1\\v_2^2
		\end{pmatrix}=
		\begin{pmatrix}
		-1 & 3\\ 1 & -3
		\end{pmatrix}
		\begin{pmatrix}
		v_2^1\\v_2^2
		\end{pmatrix}  \]
	sodass
		\[ v_1 = b_1-b_2 \text{ und } v_2 = b_13+b_2 \]
	Eigenvektoren zu den Eigenwerten $ x_1,x_2 $ liefert.

\paragraph{Rechenbeispiel 1}
	Für $ X = \begin{pmatrix}2&-1\\1&0\end{pmatrix} $ erhält man
		\[ \det(f-\id_Vx) = \det\begin{pmatrix}2-x&-1\\1&-x	\end{pmatrix} =x^2-2x+1 \]
	und Eigenvektoren zum Eigenwert $ x = 1 $ durch Lösung der LGS
		\[ \begin{pmatrix}
		2-1&-1\\1&-1
		\end{pmatrix}\begin{pmatrix}
		v_1^1\\v_1^2
		\end{pmatrix} =  \begin{pmatrix}
		1&-1\\1&-1
		\end{pmatrix}\begin{pmatrix}
		v_1^1\\v_1^2
		\end{pmatrix} \]
	d.h. der Eigenraum zum Eigenwert $ x $,
		\[ \ker(f-\id_V) = [\{b_1+b_2\}]\quad \text{ hat }\quad\dim \ker(f-\id_V)<\dim V. \]
\paragraph{Rechenbeispiel 2}
	Ist $ K=\R $ und
		\[ \det(f-\id_Vx)=x^2+1, \]
	so hat $ f $ keine Eigenwerte: z.B., wenn
		$ X=\begin{pmatrix} 0&1\\-1&0 \end{pmatrix} $.
		
\subsection{Definition} \index{Charakteristisches Polynom}
\begin{Definition}[Charakteristisches Polynom]
	Sei $ V $ ein $ K $-VR, für $ f\in\End(V) $ ist das \emph{charakteristische Polynom} von $ f $:
		\[ \chi_f(t) := \det (\id_Vt-f)\in K[t]. \]
	Analog definiert man für $ X\in K^{n\times n} $ das charakteristische Polynom
		\[ \chi_X(t) := \det (E_nt-X)\in K[t]. \]
\end{Definition}
\paragraph{Bemerkung}
	Oft wird auch das andere Vorzeichen in der Determinante verwendet, also $ \det(f-\id_Vt) $ bzw. $ \det(X-E_nt) $.
\paragraph{Bemerkung}
	\emph{Diese Definition ist erklärungsbedürftig!}
	
	Da $ t\notin K $ ist $ \id_Vt-f\notin \End(V) $, sondern $ \id_Vt-f\in\End(V)[t] $. Zwei Lösungsstrategien bieten sich an:
		\begin{enumerate}
			\item Erweiterung der Determinante auf $ \End(V)[t] $.
			\item Benutzung von Darstellungsmatrizen.
		\end{enumerate}
	Beide führen schließlich zur Leibniz-Formel:
	
	Ist $ B $ eine Basis von $ V $ und $ \xi_B^B(f) = X = (x_{ij})_{i,j\in\{1,\dots,n\}}$, so erhält man 
		\[ \chi_f(t)=\sum_{\sigma\in S_n}\sgn(\sigma)\prod_{j=1}^{n}\underset{\in K[t]}{\underbrace{\left(\delta_{\sigma(j)j}t-x_{\sigma(j)j}\right)}} \in K[t]. \]
	Die Unabhängigkeit von der Basis $ B $ folgt aus der Transformationsformel für Darstellungsmatrizen und dem Determinanten-Multiplikationssatz (wie vorher für $ \det f = \det \xi_B^B(f) $).

% VO 2016-03-15

\subsection{Bemerkung \& Definition}\index{Spur}
\begin{Definition}[Spur]
	Ist $ \dim V=n $, so ist $ \chi_f(t) $ ein normiertes Polynom vom Grad $ \deg\left(\chi_f(t)\right)=n $,
		\[ \chi_f(t)=t^n-t^{n-1}\tr f + \dots + (-1)^n\det f,\] % = \det(-f) = \chi_f(0)
	wobei die \emph{Spur} $ \tr f $ (\glqq tr \grqq $\widehat{=}$ trace) von $ f $ durch diese Gleichung (wohl-)defininiert ist.
\end{Definition}	
	Ist $ (x_{ij})_{i,j\in\{1,\dots,n\}} = X = \xi_B^B(f) $ Darstellungsmatrix von $ f $, so gilt
		\[ \tr f = \sum_{j=1}^{n}x_{jj} = \sum_{j=1}^{n} b_j^*f(b_j). \]
	Oft wird $ \det(f-\id_Vt)=(-1)^n\chi_f(t) $ als charakteristisches Polynom definiert -- dieses Polynom ist dann nur für gerade $ n $ normiert.
\subsection{Korollar}
\begin{Korollar}[Eigenwerte sind Nullstellen des char. Polynoms]
	Ein $ x\in K $ ist genau dann Eigenwert von $ f $, wenn $ \chi_f(x)=0 $.\\
	Also: Die Eigenwerte von $ f $ sind genau die Nullstellen des charakteristischen Polynoms $ \chi_f(t) $.
\end{Korollar}
\paragraph{Beweis}
	Klar -- das war die Idee hinter der Definition des charakteristischen Polynoms.
\subsection{Korollar \& Definition}\index{Algebraische/geometrische Vielfachheit}
\begin{Korollar}[Eigenwert ist Nullstelle des charakteristischen Polynoms]
	Ist $ x\in K $ Eigenwert von $ f\in\End(V) $, so ist $ (t-x) $ Teiler des charakteristischen Polynoms. Insbesondere gilt:
		\[ \exists!k\in \mathbb{N}^\times:
			\begin{cases}
				(t-x)^k\mid \chi_f(t)\\
				(t-x)^{k+1}\nmid \chi_f(t)
			\end{cases} \]
\end{Korollar}
\begin{Definition}[algebraische Vielfachheit, geometrische Vielfachheit]
	Diese Zahl $ k $ heißt die \emph{algebraische Vielfachheit} von $ x $;
		\[ g:= \dfkt(\id_Vx-f) \leq k \]
	ist die \emph{geometrische Vielfachheit} von $ x $.
\end{Definition}
\paragraph{Beweis}
	Da $ x $ Eigenwert von $ f $ ist, ist die Existenz und Eindeutigkeit von $ k $ klar. Außerdem gilt analog auch $ g\geq 1 $.
	Zu zeigen bleibt: $ g\leq k $, d.h. $ (t-x)^g \mid \chi_f(t) $:\\
	Für eine Basis $ B = (b_1,\dots,b_n) $ von $ V $ mit
	$ \ker (\id_v x - f) = [(b_1,\dots,b_g)]$
	hat
		\[ \xi_B^B(f) =
		\begin{pmatrix}
			E_gx & Y\\
			0 & X
		\end{pmatrix}
		\text{ mit } Y\in K^{g\times (n-g)}, X\in K^{(n-g)\times(n-g)} \]
	Blockgestalt, also ist
		\[ \chi_f(t)=(t-x)^g\cdot \chi_X(t), \]
	d.h. $ (t-x)^g \mid \chi_f(t)$, da $ (t-x)^{k+1}\nmid \chi_f(t) $, gilt also $ g\leq k $.
\paragraph{Beispiel}
	Ist $ f\in\End(V) $ wie oben durch $ f(B)=BX $ gegeben, so haben die Eigenwerte
		\[ x_1 = -1 \text{ und } x_2 = 3 \text{ für }
		X=\begin{pmatrix} 2 &3\\1 & 0 \end{pmatrix} \]
	algebraische und geometrische Vielfachheiten 
		\[ 1 = g_i = k_i, \text{ da } 1\leq g_i \leq k_i \text{ und } k_1+k_2 \leq 2; \]
	der Eigenwert
		\[ x=1 \text{ für } X = \begin{pmatrix} 2&-1\\1&0 \end{pmatrix} \]
	hat algebraische und geometrische Vielfachheiten $ k = 2 \text{ und } g = 1 $, da
		\[ f\neq \id_V x = \id_V \]
	und $ \chi_f(t)=(t-x)^2 \in \R[t] $, da ein quadratisches Polynom zwei (relle oder komplex konjugierte) Nullstellen hat, oder aber eine doppelte reelle.

\subsection{Definition \& Lemma}\index{$ f $-invarianter Unterraum}
	Das Schlüsselargument im Beweis oben kann man verallgemeinern:\\
\begin{Definition}[$ f $-invarianter Unterraum]
	Sei $ f\in \End(V) $ und $ U\subset V $ ein \emph{$ f $-invarianter Unterraum}, d.h. $ f(U)\subset U $. 
\end{Definition}
\begin{Lemma}[]
	Ist dann $ V=U\oplus U' $ eine direkte Zerlegung und $ p,p'\in \End(V) $ die zugehörigen Projektionen, so gilt
		\[ \chi_f(t)=\chi_{f|_U}(t)\cdot \chi_{f'}(t), \]
	wobei
		\[ f':= p'\circ f|_{U'}\in \End(U'). \]

\end{Lemma}
\paragraph{Bemerkung}
	Man kann $ f|_U $ als Endomorphismus $ f|_U\in \End(U) $ auffassen, da $ f(U)\subset U $.
\paragraph{Beweis}
	Wie oben: Sei $ B=(b_1,\dots,b_n) $ Basis von $ V $, sodass
		\begin{itemize}
			\item $ C=(b_1,\dots,b_k) $ Basis von $ U $ und
			\item $ C'=(b_{k+1},\dots,b_n) $ Basis von $ U' $ ist.
		\end{itemize}
	Die Darstellungsmatrix von $ f $ bzgl. $ B $ hat dann Blockgestalt,
		\[ \xi_B^B(f) =
			\begin{pmatrix}
				X&Y\\0&X'
			\end{pmatrix}
		\text{ mit } X=\xi_C^C(f|_U), X' = \xi_{C'}^{C'}(f') \]
	Damit folgt die Behauptung (wie oben) mit der Leibniz-Formel.
\paragraph{Bemerkung}
	Alternativ kann man das Lemma mit der von $ f $ induzierten Quotientenabbildung $ f'\in \End(V/U) $ formulieren, wobei
		\[ f':V/U\to V/U, v+U\mapsto f'(v+U) := f(v)+U. \]
\subsection{Definition}\index{Diagonalisierbarkeit}\index{Triagonalisierbarkeit}
\begin{Definition}[Diagonalisierbarkeit, Triagonalisierbarkeit von Endomorphismen]
	Ein Endomorphismus $ f\in\End(f) $ heißt \emph{diagonalisierbar} bzw. \emph{trigonalisierbar}, falls es eine Basis $ B $ von $ V $ gibt, sodass $ \xi_B^B(f)=(x_{ij})_{i,j\in\{1,\dots,n\}} $ eine Diagonalmatrix 
		\[ i\neq j\Rightarrow x_{ij} = 0 \]
	bzw. obere Dreiecksmatrix ist,
		\[ i>j \Rightarrow x_{ij} = 0. \]
\end{Definition}
\paragraph{Bemerkung}
	Falls $ \dim V<\infty $, so ist $ f\in\End(V) $ genau dann diagonalisierbar, wenn $ V $ eine Basis aus Eigenvektoren von $ f $ besitzt. Damit kann man "`Diagonalisierbarkeit"' auch im Falle $ \dim V=\infty $ definieren.
	
	%PERSONAL
	Bew: Existiert eine Eigenvektorbasis $B$, so ist $\xi_B^B$ klarerweise diagonal, mit den Eigenwerten als Diagonaleinträgen.
	Sei umgekehrt eine Matrix diagonalisierbar. Betrachtet man die diagonalisierte Matrix so stehen wieder die EW auf der Diagonalen.
	
	
\paragraph{Bemerkung}
	Ist $ f $ trigonalisierbar (oder gar diagonalisierbar), so zerfällt $ \chi_f (t) $ in Linearfaktoren: für geeignete $ x_1,\dots,x_n\in K $ ist
		\[ \chi_f(t)=\prod_{j=1}^{n}(t-x_j). \]
	
	%PERSONAL
	Bew: Transformiert man die Darstellungsmatrix von $f$ auf die diagonalisierte Gestalt und bildet die polynomwertige Matrix so folgt über unseren Zugang zum charakteristischen Polynom über die Leibnizformel, dass nur noch das Produkt der Diagonaleinträge stehen bleibt, analog zur Eigenschaft der Determinante für "`normale'" Matrizen.

\subsection{Bemerkung \& Definition}
\begin{Definition}[Diagonalisierbarkeit, Triagonalisierbarkeit von Matrizen]
	Man nennt eine Matrix $ X\in K^{n\times n} $ diagonalisierbar (bzw. trigonalisierbar), falls $ f_X\in \End(K^n) $ diagonalisierbar (bzw. trigonalisierbar) ist.
\end{Definition}	

	Dies ist genau dann der Fall, falls es $ P\in Gl(n) $ gibt, sodass $ PXP^{-1} $ Diagonalmatrix (bzw. obere Dreiecksmatrix) ist.

% VO 2016-03-17

\subsection{Lemma}
	Frage: Was sind hinreichende Kriterien dafür? Notwendigkeit kennen wir: $ \chi_f(t) $ zerfällt in Linearfaktoren.
	
	\begin{Lemma}[Lineare Unabhängigkeit von Eigenvektoren]
		Eigenvektoren $ v_1,\dots,v_m\in V $ zu paarweise verschiedenen Eigenwerten $ x_1,\dots,x_m $ eines Endomorphismus $ f\in\End(V) $ sind linear unabhängig.
	\end{Lemma}
\paragraph{Bemerkung}
	Anders gesagt: Die Summe von Eigenräumen zu paarweise verschiedenen Eigenwerten ist direkt.
\paragraph{Beweis}
	Zu zeigen: Ist $ \sum_{i=1}^m v_iy_i = 0 $ für Koeffizienten $ y_1,\dots,y_m\in K $, so folgt $ y_1 = \dots = y_m = 0 $.\\	
	Seien $ y_1,\dots,y_m \in K $ und $ w_i := v_iy_i $ und $ w:= \sum_{i=1}^{m}w_i = \sum_{i=1}^{m}v_iy_i$.
	Wiederholte Anwendung von $ f $ liefert, wegen $ f(w_i) = w_ix_i $
	
		\[ (f^{m-1}(w),\dots,f^2(w),f(w),w) = (w_1,\dots,w_m)
		\begin{pmatrix}
		 x_1^{m-1}&\cdots&x_1^2&x_1&1 \\
		 \vdots&\ddots&\vdots&\vdots&\vdots\\
		 x_m^{m-1}&\cdots&x_m^2&x_m & 1
		\end{pmatrix} \]
	mit der Vandermonde-Matrix $ X\in Gl(m) $, da
		\[ \det X = \prod_{i<j} (x_i - x_j)\neq 0 \]
	weil die Eigenwerte $ x_1,\dots,x_m $ paarweise verschieden sind.
	Damit folgt aus $ w=\sum_{i=1}^{m}v_iy_i = 0 $
		\[ (w_1,\dots,w_m)=(f^{m-1}(w),\dots,f(w),w)X^{-1} = (0,\dots,0) \]
	also
		\[ \forall i=1,\dots,m: 0 = w_i = v_iy_i \text{ und }v_i \neq 0 \Rightarrow y_i = 0.  \]
\subsection{Satz}
    \begin{Satz}[Diagonalisierbarkeit eines Endomorpismus]
		Ein Endomorphismus $ f\in \End(V) $ ist genau dann diagonalisierbar, wenn $ \chi_f(t) \in K[t] $ in Linearfaktoren zerfällt und die algebraischen und geometrischen Vielfachheiten aller Eigenwerte übereinstimmen,
			\[ \chi_f(t) = \prod_{i=1}^{m}(t-x_i)^{k_i} \text{ und } \forall i=1,\dots,m: k_i = g_i.\]
	\end{Satz}
\paragraph{Beweis}
	Ist $ f $ diagonalisierbar, so existiert eine Basis $ B $ aus Eigenvektoren von $ f $, also ist dann
		\[ \xi_B^B(f) =
			\begin{pmatrix}
				E_{g_1}x_1 &0& \cdots & 0 \\
				0 &E_{g_2}x_2& \ddots & \vdots\\
				\vdots & \ddots& \ddots & \vdots\\
				0 & 0 & \cdots & E_{g_m}x_m 
			\end{pmatrix} \]
	Damit ist
		\[ \chi_f(t)=\prod_{i=1}^{m}(t-x_i)^{g_i}. \]
	Hat andererseits das charakteristische Polynom diese Gestalt, so wähle man in jedem Eigenraum $ \ker(\id_Vx_i-f) $ eine Basis $ C_i,i=1,\dots,m $. Da Eigenvektoren zu verschiedenen Eigenwerten linear unabhängig sind, und wegen
		\[ g_1+\dots+g_m = k_1 + \dots + k_m = \dim V \]
	liefert $ B := \bigcup_{i=1}^mC_i $ eine Basis von $ V $.
\subsection{Korollar}
	\begin{Korollar}
		Ein Endomorphismus $ f\in\End(V) $ mit $ n=\dim V $ paarweise verschiedenen Eigenwerten ist diagonalisierbar.
	\end{Korollar}
\paragraph{Beweis}
	Für die geometrischen und algebraischen Vielfachheiten jedes Eigenwerts gilt
		\[ 1\leq g_i \leq k_i \text{ und } \sum_{i=1}^{n}k_i \leq n. \]
	Damit folgt
		\[ \forall i=1,\dots,n:k_i = 1 \text{ und } \sum_{i=1}^{n}k_i = n, \]
	d.h. das charakteristische Polynom zerfällt in Linearfaktoren und $ \forall i=1,\dots,n:k_i=g_i. $
\subsection{Satz}
\begin{Satz}[Trigonalisierbarkeit eines Endomorpismus]
	Ein Endomorphismus $ f\in\End(V) $ ist genau dann trigonalisierbar, wenn das charakteristische Polynom in Linearfaktoren zerfällt.
\end{Satz}
\paragraph{Bemerkung}
	Da Diagonalisierbarkeit bzw. Trigonalisierbarkeit durch die Existenz einer Darstellungsmatrix in spezieller Gestalt definiert wurde, wird in den Charakterisierungen immer (implizit) $ \dim V < \infty $ angenommen.
\paragraph{Beweis}
	Wir wissen schon: Ist $ f $ trigonalisierbar, so zerfällt $ \chi_f(t) $ in Linearfaktoren. Umkehrung: Beweis durch vollständige Induktion über $ n=\dim V $.\\
	Für $ n=1 $ ist nichts zu zeigen. Sei die Behauptung für $ n-1 $ bewiesen. Für $ n $ folgt dann:\\
	Da $ \chi_f(t) $ in Linearfaktoren zerfällt
		\[ \chi_f(t)=\prod_{i=1}^{n}(t-x_i) \]
	für geeignete $ x_1,\dots,x_n $, ist $ x_1 $ Eigenwert von $ f $. Nun seien
	\begin{itemize}
		\item $ b_1 $ ein Eigenvektor zum Eigenwert $ x_1 $ und $ U:= [\{b_1\}] $,
		\item $ U'\subset V $ ein zu $ U $ komplementärer Unterraum, und
		\item $ p,p'\in \End(V) $ die zur direkten Zerlegung $ V = U\oplus U' $ gehörenden Projektionen,
			\[ U = p(V) = \ker p' \text{ und } U' = p'(V) = \ker p, \]
		\item und $ f' := p'\circ f|_{U'}\in\End(U'). $
	\end{itemize}
	Da $ U (\neq \{0\}) $ $ f $-invarianter UR von $ V $ ist, faktorisiert das charakteristische Polynom
		\[ \chi_f(t)=\chi_{f|_U}(t)\cdot \chi_{f'}(t) = (t-x_1)\cdot \chi_{f'}(t); \]
	also zerfällt $ \chi_{f'}(t) $ in Linearfaktoren,
		\[ \chi_{f'}(t)=\prod_{i=2}^{n}(t-x_i). \]
	Nach Induktionsannahme existiert also eine Basis $ B' = (b_2,\dots,b_n) $ von $ U' $, sodass $ \xi_{B'}^{B'}(f) $ obere Dreiecksmatrix ist. Mit $ B=(b_1,\dots,b_n) $ als Basis von $ V $ gilt dann:
		\[ \xi_B^B (f) =
			\begin{pmatrix}
			x_1& Y\\
			0 & \xi_{B'}^{B'}(f')
			\end{pmatrix} \]
	ist obere Dreiecksmatrix.