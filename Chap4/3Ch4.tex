%VO1-2016-03-01
\setcounter{chapter}{3}
\chapter{Volumenmessung}
\setcounter{section}{2}
\section{Polynome \& Polynomfunktionen}
	Warum? (Vielleicht eher "`Algebra"' -- allgemein -- als "`lineare"' Algebra) Wichtig: das charakteristische Polynom eines Endomorphismus -- wichtiges Hilfsmittel im Kontext der Struktursätze.
\paragraph{Beispiel}
	Wir definieren Polynomfunktionen $ p,q: K\to K $ eines Körpers $ K $ in sich durch 
		\begin{align*}
		p:\ & K\to K,\ x\mapsto p(x):= 1+x+x^2\\
		q:\ & K\to K,\ x\mapsto q(x):= 1
		\end{align*}
	Falls $ K=\mathbb{Z}_2 $ so gilt dann
		\begin{align*}
		&\forall x\in K: x(x+1)=0\\
		\Rightarrow\ &\forall x\in K: p(x) = q(x)
		\end{align*}
	d.h., unterschiedliche "`Polynome"' liefern die gleiche Polynomfunktion: Koeffizientenvergleich funktioniert nicht.
\paragraph{Wiederholung}
	Auf dem Folgenraum $ K^\mathbb{N} $ betrachten wir die Familie $ (e_k)_{k\in \mathbb{N}} $ mit
		\[ e_k :\mathbb{N}\to K,\ j\mapsto e_k(j):= \delta_{jk} \]
	Wir wissen: $ (e_k)_{k\in \mathbb{N}} $ ist linear unabhängig, aber kein Erzeugendensystem:
		\[ \forall k\in \mathbb{N}: e_k \notin [(e_j)_{j\neq k}] \text{ und }
		[(e_j)_{j\in\mathbb{N}}]\neq K^{\mathbb{N}}\]
	Insbesondere gilt:
		\[ \forall x\in [(e_j)_{j\in \mathbb{N}}]\ \exists n\in \mathbb{N}\ \forall k>n : x_k = 0 \]
\subsection{Idee \& Definition} \index{Polynom}\index{Cauchyprodukt}
	\begin{Definition}[Cauchyprodukt]
		Wir fassen ein Polynom als (endliche) Koeffizientenfolge auf,
		\[ \sum_{k=0}^{n} t^ka_k \cong
		\sum_{k\in \mathbb{N}}e_ka_k \text{ mit } a_k = 0 \text{ für } k>n \]
	und führen darauf das \emph{Cauchyprodukt} (vgl. Analysis) als Multiplikation ein:
		\[ (a_k)_{k\in \mathbb{N}} \odot (b_k)_{k\in \mathbb{N}} := (c_k)_{k\in \mathbb{N}} \]
	wobei
		\[ c_k := \sum_{j=0}^{k}a_jb_{k-j}. \]
	\end{Definition}
	Insbesondere gilt damit
		\begin{gather*}
		\forall j,k\in \mathbb{N}: e_j \odot e_k = e_{j+k}
		\Rightarrow \forall k\in \mathbb{N}:
			\begin{cases}
				e_0 \odot e_k = e_k\\
				e_1^k = \underset{k \text{ mal}}{\underbrace{e_1 \odot \cdots \odot e_1}} = e_k
			\end{cases}
		\end{gather*}
	Mit $ 1:= e_0,\ t:= e_1 $ und $ t^0 := 1 $, wie üblich, liefert dies:
		\[ \sum_{k=0}^{n}t^ka_k = \sum_{k\in \mathbb{N}}e_ka_k \in [(e_k)_{k\in \mathbb{N}}]\subset K^\mathbb{N} \]
\subsection{Definition}\index{Polynom!-algebra}\index{Polynom!Grad}\index{Polynom!normiertes}
		\begin{Definition}[Polynomalgebra]
			\[ K[t] := ([(e_k)_{k\in \mathbb{N}}],\odot) ,\]
	mit dem Cauchyprodukt $ \odot $, ist die \emph{Polynomalgebra} über dem Körper $ K $; die Elemente von $ K[t] $,
		\[ p(t) = \sum_{k=0}^{n}t^ka_k = \sum_{k\in\mathbb{N}}e_ka_k, \]
	heißen \emph{Polynome in der Variablen} $ t:= e_1 $.
	Der \emph{Grad} eines Polynoms ist
		\[  \deg\sum_{k=0}^{n}t^ka_k := \max \{k\in \mathbb{N}\mid a_k \neq 0\}  \quad \left( \text{bzw. } \deg 0 := -\infty \right) \]
	Ist (der "`höchste"' Koeffizient) $ a_n = 1 $ für $ \deg p(t) = n $, so heißt das Polynom $ p(t) $ \emph{normiert}.
		\end{Definition}
\paragraph{Notation}
	Mit $t^k = e_{k}$, also $ K[t] = [(e_k)_{k\in \mathbb{N}}] $
	wird das Cauchyprodukt auf $ K[t] $ eine "`normale"' Multiplikation, gefolgt von einer Sortierung nach den Potenzen der Variablen $ t $. Wir werden das "`$ \odot $"' daher oft unterdrücken, und z.B. $ p(t)q(t) $ schreiben, anstelle von $ p(t) \odot q(t) $.
\paragraph{Bemerkung (Koeffizientenvergleich)}
	Mit dieser Definition von "`Polynom"' gilt
		\begin{align*}
			p(t)=\sum_{k=0}^{n}t^ka_k = 0
			\quad\Rightarrow \forall k\in \mathbb{N}: a_k = 0,
		\end{align*}
	da $ (t^k)_{k\in \mathbb{N}} = (e_k)_{k\in \mathbb{N}}$ linear unabhängig ist.
	Koeffizientenvergleich funktioniert!
\paragraph{Bemerkung}
	Die Polynomalgebra $ K[t] $ über $ K $ ist eine assoziative und kommutative $ K $-Algebra, weiters ist $ K[t] $ unitär mit Einselement $ 1=e_0 $.
\subsection{Definition}\index{Algebra}
	\begin{Definition}[Algebra]
		Eine $ K $-Algebra ist ein $ K $-VR mit einer \emph{bilinearen Abbildung},
		\[ \odot: V\times V \to V,\ (v,w)\mapsto v\odot w, \]
	d.h. es gilt
		\begin{enumerate}[(i)]
			\item $ \forall w\in V:\ V\ni v\mapsto v\odot w\in V $ ist linear;
			\item $ \forall v\in V: V\ni w\mapsto v\odot w\in V $ ist linear.
		\end{enumerate}
	
	Eine $ K $-Algebra heißt
		\begin{itemize}
			\item unitär (mit Einselement 1), falls
                              \[\exists 1\in V^\times\forall v\in V: 1\odot v = v\odot 1 = v\]
			\item assoziativ, falls
                              \[\forall u,v,w\in V: (u\odot v)\odot w = u\odot (v\odot w)\]
			\item kommutativ, falls
                              \[\forall v,w,\in V: v\odot w = w\odot v\]
		\end{itemize}
	\end{Definition}
\paragraph{Beispiel}
	$ \End(V) $ ist (mit Komposition) eine unitäre assoziative Algebra.
\paragraph{Bemerkung}
	In jeder Algebra $ (V,\odot) $ gilt:
		\[ \forall v\in V: 0\odot v = v\odot 0 = 0 \]
	da z.B. für $ v\in V $ gilt
		\[ v\odot 0 = v\odot (0+0) = v\odot 0 + v\odot 0 \ \Rightarrow\  0=v\odot 0\]
	Ist $ (V,\odot) $ unitär, so liefert $ [1]\subset V $ wegen $ 1\odot 1 = 1 $ einen Körper:
		\[ ([1], +\mid_{[1]\times [1]},\odot\mid_{[1]\times [1]} ) \cong K \]
	vermöge $ K\ni x \mapsto 1 \cdot x\in [1] $ (siehe Aufgabe 5).
\subsection{Definition}\index{Algebra!-Homomorphismus}
	\begin{Definition}[Algebra-Homomorphismus]
		Ein \emph{Algebra-Homomorphismus} zwischen $ K $-Algebren $ (V,\odot) $ und $ (W,*) $ ist eine lineare Abbildung $ \psi\in \hom(V,W) $, für die gilt:
		\[ \forall v,v' \in V: \psi(v\odot v')=\psi(v)*\psi(v') \]
	\end{Definition}
\paragraph{Bemerkung}
	$ \hom(V,W) $ wird oft auch für den (Vektor-)Raum der Algebra-Homomorphismen verwendet. In dieser LVA bedeutet "`$ \hom(V,W) $"' immer VR-Homomorphismen, bei allen "`anderen"' Homomorphismen wird  erwähnt, was gemeint ist.

%VO2-2016-03-03

\subsection{Einsetzungssatz \& Definitionen}
	\begin{Satz}[Einsetzungssatz]\index{Einsetzungshomomorphismus}\index{Polynom!-funktion}
		Seien $ (V,\odot) $ eine unitäre assoziative Algebra und $ v\in V $. Dann ist
			\[ \psi_v: K[t]\to V,\ \sum_{k=0}^{n}t^ka_k = p(t)\mapsto \psi_v(p(t)) := \sum_{k=0}^{n}v^ka_k \]
		-- wobei $ v^0 = 1 $ sinnvoll ist, da die Algebra unitär ist -- ein Algebra-Homomorphismus; $ \psi_v $ heißt \emph{Einsetzungshomomorphismus}. 
			\[ p:V\to V,\ v\mapsto p(v) := \psi_v(p(t)) \]
		heißt die zu $ p(t)\in K[t] $ gehörige \emph{Polynomfunktion} auf $ V $.
	\end{Satz}
\paragraph{Bemerkung}
	Wie üblich: $ v^k := \underset{k-\text{mal}}{\underbrace{v\odot\cdots \odot v}} $ und $ v^0 := 1 $.
\paragraph{Beweis}
	\begin{enumerate}
		\item $ \psi_v $ ist linear:
			\begin{itemize}
				\item für $ p(t) = \sum_{k\in\mathbb{N}} t^ka_k $ und $ a\in K $ gilt:
					\[ \psi_v(p(t)a) = \psi_v\Big(\sum_{k\in\mathbb{N}} t^ka_ka\Big) = \sum_{k\in\mathbb{N}} v^ka_ka = \psi_v(p(t))a; \]
				\item für $ p(t) = \sum_{k\in\mathbb{N}} t^ka_k $ und $ q(t) = \sum_{k\in\mathbb{N}} t^k b_k $ gilt:
					\[ \psi_v(p(t)+q(t)) = \psi_v\Big(\sum_{k\in\mathbb{N}}t^k(a_k+b_k)\Big) = \sum_{k\in\mathbb{N}} v^k(a_k+b_k) = \psi_v(p(t))+\psi_v(q(t)) \]
			\end{itemize}
		\item $ \psi_v $ ist "`multiplikativ"', d.h. verträglich mit der beteiligten Multiplikation:
		
			Für die Vektoren der Basis $ (t^k)_{k\in\mathbb{N}} $ von $ K[t] $ gilt, da $ (V,\odot) $ assoziativ ist,
				\[ \psi_v(t^mt^n) = \psi_v(t^{m+n}) = v^{m+n} = v^m\odot v^n = \psi_v(t^m)\odot \psi_v(t^n). \]
			Da aber $ \psi_v $ linear und die Multiplikation in $ K[t] $ und in $ (V,\odot) $ bilinear sind, folgt die Behauptung.
	\end{enumerate}
\paragraph{Bemerkung (Fortsetzungssatz für bilineare Abbildungen)}\index{Fortsetzungssatz für bilineare Abbildungen}
	Im Beweis haben wir verwendet: Die Abbildungen
		\[ K[t]\times K[t]\to V,\ (p(t),q(t))\mapsto
			\begin{cases}
			\psi_v(p(t)q(t)) &\text{(Cauchyprodukt)}\\
			\psi_v(p(t))\odot \psi_v(q(t)) &\text{(Produkt in $ (V,\odot) $)}
			\end{cases} \]
	sind bilinear (da $ \psi_v $ linear ist), sind also gleich, sobald sie auf einer Basis übereinstimmen.
	Dies ist die Eindeutigkeit eines Fortsetzungssatzes für bilineare Abbildungen:
	
	\begin{Satz}[Fortsetzungssatz für bilineare Abbildungen]
	Sind $ V,W\ K$-VR, $ (b_i)_{i\in I} $ eine Basis von $ V $ und $ (\beta_{ij})_{i,j\in I} $ eine Familie in $ W $, so gibt es eine eindeutige bilineare Abbildung
		\[ \beta: V\times V\to W \]
	mit
		\[ \forall i,j\in I: \beta(b_i,b_j) = \beta_{ij} \]
	\end{Satz}
	
	Dieser Fortsetzungssatz folgt direkt aus dem Fortsetzungssatz für lineare Abbildungen, da
		\[ \{\beta:V\times V\to W \text{ bilinear}\} \cong \hom(V,\hom(V,W))\]
	vermittels des Isomorphismus
		\[ \beta \mapsto \big(v\mapsto\underset{\in \hom(V,W)}{\underbrace{\beta(v,.)}}\big), \]
	d.h. durch Nacheinandereinsetzen der Argumente.
\paragraph{Bemerkung}
	Die Abbildung eines Polynoms auf seine Polynomfunktion auf dem Körper,
		\[ K[t]\ni p(t)\mapsto (x\mapsto p(x))=\psi_x(p(t))\in K^K \]
	ist für $ \Char K\neq 0 $ nicht injektiv\footnote{sonst wäre $K^K$ unendlich dimensional.}. Das heißt: Koeffizientenvergleich (für Polynomfunktionen) kann nur funktionieren, wenn $ \Char K = 0 $.
\paragraph{Beispiel \& Bemerkung}\index{Einsetzungshomomorphismus}
	Ist $ V\ K $-VR, so ist $ \End(V) $ eine $ K $-Algebra (mit Komposition $ \circ $). Man erhält also für $ f\in \End(V) $ einen Einsetzungshomomorphismus
		\[ \psi_f: K[t]\to \End(V),\ p(t) \mapsto \psi_f(p(t)) = p(f); \]
	und für jedes Polynom $ p(t)\in K[t] $ eine zugehörige Polynomfunktion
		\[ p: \End(V)\to\End(V),\ f\mapsto \psi_f(p(t))= p(f). \]
	Dieses Beispiel ist der Schlüssel zum Satz von Cayley-Hamilton (im nächsten Abschnitt).
\subsection{Lemma}
	\begin{Lemma}
		Für Polynome $ p(t), q(t)\in K[t] $ gilt:
			\begin{itemize}
				\item $ \deg p(t)\odot q(t) = \deg p(t)+\deg q(t) $,
				\item $ \deg p(t)+q(t) \leq \max\{\deg p(t), \deg q(t)\} $.
			\end{itemize}
	\end{Lemma}
\paragraph{Beweis}
	Für $ p(t) = \sum_{k\in\mathbb{N}}t^ka_k $ und $ q(t) = \sum_{k\in\mathbb{N}}t^kb_k $ ist
		\[ p(t)\odot q(t) = \sum_{k\in\mathbb{N}}t^kc_k \text{ mit } c_k = \sum_{j=0}^{k}a_jb_{k-j} \]
	Gilt nun $ \deg p(t) = n $ und $ \deg q(t) = m $, d.h.
		\[ a_n,b_m \neq 0 \land \forall k>n, k'>m:a_k = b_{k'}=0 \] 
	so folgt
		\[ \left.
		\begin{aligned}
		\forall k>m+n : c_k = 0\ \\
		        c_{m+n} = a_nb_m\ \\
		\end{aligned}
		 \right\}
		\Rightarrow \deg p(t)\odot q(t) = m+n \]
	Gilt andererseits $ \deg p(t) = -\infty $ oder $ \deg q(t) = -\infty $, also $ p(t) = 0 \lor q(t) = 0 $,
	so folgt
		\[ p(t)\odot q(t) = 0 \Rightarrow \deg p(t)\odot q(t) = -\infty. \]
	Die zweite Behauptung ist offensichtlich wahr.

%VO3-2016-03-08

\paragraph{Beispiel}
	Für $ p(t),q(t),d(t)\in K[t] $ mit $ d(t)\neq 0 $ gilt
		\[ d(t)p(t) = d(t)q(t)\Rightarrow p(t)=q(t). \]
	Nämlich: da $ \deg d(t) \geq 0$,
		\begin{align*}
			-\infty &= \deg d(t)\big(p(t)-q(t)\big)\\
			&= \deg d(t)+ \deg\big(p(t)-q(t)\big)\\
			\Rightarrow \deg\big(p(t)-q(t)\big) &= -\infty\\
			\Rightarrow p(t)&=q(t)
		\end{align*}
\subsection{Euklidischer Divisionsalgorithmus}\index{Polynom!-division}
	\begin{Satz}[Euklidischer Divisionsalgorithmus (Polynomdivision)]
	Seien $ p(t), d(t) \in K[t],\ d(t) \neq 0$. Dann existieren eindeutig $ q(t), r(t) \in K[t] $, sodass
		\[ p(t)= d(t)q(t) + r(t) \text{ und } \deg r(t) < \deg d(t). \]
	\end{Satz}
\paragraph{Bemerkung}
	Ist $ \deg p(t)\leq \deg d(t) $, so ist die Aussage trivial.
\paragraph{Beweis}
	Eindeutigkeit folgt wie im Beispiel; mit
		\begin{gather*}
		p(t) =
			\begin{cases}
				d(t)q(t)+r(t)\\
				d(t)\tilde{q}(t)+\tilde{r}(t)
			\end{cases}\\
		\Rightarrow d(t)\big(q(t)-\tilde{q}(t)\big) = \tilde{r}(t)-r(t)
		\end{gather*}
	erhält man
		\begin{gather*}
			\deg d(t) + \deg \big(q(t)-\tilde{q}(t)\big) = \deg (r(t)-\tilde{r}(t))\\
			\leq \max \{\deg r(t), \deg \tilde{r} (t)\} < \deg d(t).
		\end{gather*}
	Also folgt
		\[ \deg\big(q(t)-\tilde{q}(t)\big) = -\infty \Rightarrow \deg (r(t)-\tilde{r}(t)) = \deg d(t) -\infty = - \infty \]
	und damit
		\[ \tilde{q}(t)=q(t) \text{ und }\tilde{r}(t) = r(t). \]
	
	Existenz: Mit $ k := \deg d(t) \geq 0 $ und
		\[ K[t]_m := \{q(t)\in K[t]\mid \deg q(t)\leq m \} \text{ für }m\in \mathbb{N} \]
	betrachte man die Abbildung
		\[ K[t]_m \times K[t]_{k-1}\to K[t]_{k+m},\ \big(q(t), r(t)\big) \mapsto d(t)q(t)+r(t). \]
	Diese Abbildung ist linear (klar) und injektiv, denn:
	ist $ q(t) \neq 0 $, so folgt wegen
		\[ \deg r(t) < k = \deg d(t)\leq \deg d(t)q(t) \]
	dass %Anm.: da wegen des kleineren Grades der höchste Koeffizient durch die Addition nicht verschwinden kann
		\begin{gather*}
			\deg \big(d(t)q(t) + r(t)\big) = \deg d(t)q(t)\geq k > -\infty\\
			\Rightarrow d(t)q(t)+r(t)\neq 0,
		\end{gather*}
	also
		\[ d(t)q(t)+r(t)=0 \Rightarrow q(t)=0 \land r(t) = 0. \] %Damit ist der Kern der Abbildung \{0\} -> Injektivität
	Wegen
		\[ \dim K[t]_m \times K[t]_[k-1] = (m+1) + k = (k+m) + 1 = \dim K[t]_{k+m} \]
	liefert diese Abbildung dann für jedes $ m\in \mathbb{N} $ einen Isomorphismus
		\[ K[t]_m \times K[t]_{k-1} \to K[t]_{k+m} \]
\subsection{Korollar \& Definition}
	\begin{Definition}[Nullstelle]\index{Nullstelle}
	Sei $ p(t)\in K[t] $ mit $ \deg p(t)\geq 1 $. Ist $ x\in K $ eine \emph{Nullstelle} von $ p(t) $, d.h.
		\[ p(x) = \psi_x(p(t)) = 0, \]
	\end{Definition}
	so folgt
	\begin{Korollar}[Abspalten von Linearfaktoren mit Hilfe von Nullstellen]
		\[ \exists! q(t)\in K[t]: p(t) = (t-x) q(t) \]
	\end{Korollar}
\paragraph{Beweis}
	Seien $ p(t)\in K[t] $ mit $ \deg p(t) \geq 1 $ und $ x\in K $ eine Nullstelle von $ p(t) $; dann gibt es eindeutig $ q(t),r(t) \in K[t] $ mit
		\[ p(t) = (t-x) q(t) + r(t) \text{ und } \deg r(t) < \deg (t-x) = 1, \]
	also
		\[ p(t) = (t-x)q(t)+r(t) = (t-x)q(t)+c_0. \]
	Einsetzen von $ x\in K $ liefert dann
		\[ 0 = p(x) = (x-x)q(x) + c_0 = c_0 \]
\paragraph{Bemerkung und Beispiel}\index{Linearfaktorisierung}
	Dies liefert eine Methode, um Polynome zu \emph{faktorisieren}: Für jede gefundene Nullstelle kann man einen \emph{Linearfaktor} abspalten.
		\[ p(t)= t^4-t^3+t^2-t =
			\begin{cases}
				t(t-1)(t-i)(t+i) \in \mathbb{C}[t]\\
				t(t-1)(t^2+1) \in \mathbb{R}[t]
			\end{cases} \]
\subsection{Mehr zu Polynomen}
	Dies ist der Anfang einer der Teilbarkeitstheorie der natürlichen Zahlen ähnlichen Theorie für Polynome.
	
	\begin{Definition}[Teiler]
	\begin{addmargin}{1cm}
		\textit{Sind $ p(t),d(t)\in K[t] $, so heißt $ d(t) $ \emph{Teiler} von $ p(t), d(t)\mid p(t) $, falls
			\[ \exists q(t)\in K[t]: p(t)= d(t)q(t). \]}
	\end{addmargin}
	\end{Definition}
\paragraph{Primpolynome}\index{Primpolynome}
	Nennt man $ p(t)\in K[t] $ mit $ \deg p(t) > 0$ ein \emph{Primpolynom} (oder \emph{irreduzibel}), falls für $ d(t),q(t)\in K[t] $ gilt:
		\[ p(t)= d(t)q(t) \Rightarrow \Big( \deg q(t)=0 \lor \deg d(t) = 0 \Big), \]
	so gilt der Satz über die \emph{Primfaktorzerlegung}:
	
	\begin{Satz}[Primfaktorzerlegung]
	\begin{addmargin}{1cm}
		\textit{Jedes Polynom $ p(t)\in K[t] $ mit $ \deg p(t)>0 $ zerfällt eindeutig in Primpolynome,
			\[ p(t) = a_n p_1(t) \cdots p_m(t), \]
		wobei $ a_n\in K $ und $ p_1(t),\dots,p_m(t)\in K[t] $ normierte Primpolynome sind.}
	\end{addmargin}
	\end{Satz}
	
\paragraph{Beweis}	
	Existenz ist einfach zu zeigen (Induktion über $ n $), die weniger leicht zu zeigende Eindeutigkeit benutzt die Existenz des \emph{größten gemeinsamen Teilers} $ d(t) = \ggT\big(p(t),q(t)\big) $ zweier Polynome $ p(t) $ und $ q(t) $:
	
	\begin{addmargin}{1cm}
		\textit{Zu $ p(t),q(t) \in K[t]\setminus \{0\} $ gibt es genau ein normiertes Polynom $ d(t)\in K[t] $ mit
			\begin{align*}
				d(t)&\mid p(t)\land d(t)\mid q(t) \text{ und}\\
				d'(t)&\mid p(t)\land d'(t)\mid q(t) \Rightarrow d'(t)\mid d(t).
			\end{align*}}
	\end{addmargin}
\paragraph{Lemma von B\'ezout}
	\begin{Lemma}[Lemma von B\'ezout]
	Für den $ \ggT $ gilt auch das Lemma von B\'ezout:
		\[ \exists p'(t),q'(t)\in K[t]: d(t)=p(t)p'(t)+q(t)q'(t) \]
	\end{Lemma}
\paragraph{Bemerkung}
	Aus der Gradformel,
		\[ \deg d(t)q(t) = \deg d(t)+\deg q(t) \]
	folgt direkt:
		\begin{addmargin}{1cm}
			\textit{Jedes Polynom $ p(t)\in K[t] $ mit $ \deg p(t)=1 $ ist Primpolynom.}
		\end{addmargin}

\paragraph{Fundamentalsatz der Algebra}
	Falls $ K = \mathbb{C} $, so sind die Polynome mit Grad 1 die einzigen Primpolynome:
		\begin{Satz}[Fundamentalsatz der Algebra]
		\begin{addmargin}{1cm}
			\textit{In $ \mathbb{C} $ zerfällt jedes Polynom (mit Grad $ \geq 1 $) in Linearfaktoren;
				\[ \forall p(t)\in \mathbb{C}[t],\ \deg \geq 1:\ \exists x_1,\dots,x_n \in \mathbb{C} \]
			mit
				\[ p(t) = a_n \prod_{j=1}^{n}(t-x_j) \]}
		\end{addmargin}
		\end{Satz}
	Ist $ K=\mathbb{R} $, so ist dies nicht der Fall; ein Primpolynom vom Grad $ \deg p(t) = 2 $ ist z.B.
		\[ p(t) = t^2+1\ \in \mathbb{R}[t], \]
	denn
		\[ t^2+1 = (t-x_1)(t-x_2) \Rightarrow
			\begin{cases}
				0 = x_1 + x_2\\
				1 = x_1 \cdot x_2
			\end{cases}
		\Rightarrow 1 = -x^2 \]
	Andererseits ist $ p(t)\in \mathbb{R}[t]\subset \mathbb{C}[t], $
	also existieren $ x_1,\dots,x_n\in \mathbb{C} $ mit
		\[ a_n\prod_{j=1}^{n}(t-x_j) = p(t) = \overline{p(t)} = \overline{a_n}\prod_{j=1}^{n}(t-\overline{x_j}), \]
	d.h. mit der Eindeutigkeit der Primfaktorzerlegung, $ a_n\in \mathbb{R} $ und die $ x_j $ sind entweder reell oder treten in komplex-konjugierten Paaren auf:
		\[ p(t) = a_n\prod_{j=1}^{m}(t^2-t(x_j+\overline{x_j})+x_j\overline{x_j})\prod_{j=2m+1}^{n}(t-x_j). \]
	Ist also $ p(t) \in \mathbb{R}[t] $ Primpolynom, so folgt $ \deg p(t)\leq 2 $ und
		\[ \deg p(t) = 2 \Rightarrow \exists x,y\in \mathbb{R}: p(t) = (t-x)^2+y^2 \text{ mit } y\neq 0\]
	In $ K=\mathbb{Q} $ gibt es noch "`mehr"' Primpolynome, wie z.B.:
		\[ p(t) = t^2-2 \text{ oder } p(t) = t^4+1 \]