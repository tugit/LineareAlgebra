%VO1-2016-03-01
\setcounter{chapter}{3}
\chapter{Volumenmessung}
\setcounter{section}{2}
\section{Polynome \& Polynomfunktionen}
	Warum? (Vielleicht eher "`Algebra"' -- allgemein -- als "`lineare"' Algebra) Wichtig: das charakteristische Polynom eines Endomorphismus -- wichtiges Hilfsmittel im Kontext der Struktursätze.
\paragraph{Beispiel}
	Wir definieren Polynomfunktionen $ p,q: K\to K $ eines Körpers $ K $ in sich durch 
		\begin{align*}
		p:\ & K\to K,\ x\mapsto p(x):= 1+x+x^2\\
		q:\ & K\to K,\ x\mapsto q(x):= 1
		\end{align*}
	Falls $ K=\mathbb{Z}_2 $ so gilt dann
		\begin{align*}
		&\forall x\in K: x(x+1)=0\\
		\Rightarrow\ &\forall x\in K: p(x) = q(x)
		\end{align*}
	d.h., unterschiedliche "`Polynome"' liefern die gleiche Polynomfunktion: Koeffizientenvergleich funktioniert nicht.
\paragraph{Wiederholung}
	Auf dem Folgenraum $ K^\mathbb{N} $ betrachten wir die Familie $ (e_k)_{k\in \mathbb{N}} $ mit
		\[ e_k :\mathbb{N}\to K,\ j\mapsto e_k(j):= \delta_{jk}; \]
	wir wissen: $ (e_k)_{k\in \mathbb{N}} $ ist linear unabhängig, aber kein Erzeugendensystem:
		\[ \forall k\in \mathbb{N}: e_k \notin [(e_j)_{j\neq k}] \text{ und }
		[(e_j)_{j\in\mathbb{N}}]\neq K^{\mathbb{N}}\]
	Insbesondere gilt:
		\[ \forall x\in [(e_j)_{j\in \mathbb{N}}]\ \exists n\in \mathbb{N}\ \forall k>n : x_k = 0 \]
\subsection{Idee \& Definition} \index{Polynom}\index{Cauchyprodukt}
	\begin{Definition}[Cauchyprodukt]
		Wir fassen ein Polynom als (endliche) Koeffizientenfolge auf,
		\[ \sum_{k=0}^{n} t^ka_k \cong
		\sum_{k\in \mathbb{N}}e_ka_k \text{ mit } a_k = 0 \text{ für } k>n \]
	und führen darauf das \emph{Cauchyprodukt} (vgl. Analysis) als Multiplikation ein:
		\[ (a_k)_{k\in \mathbb{N}} \odot (b_k)_{k\in \mathbb{N}} := (c_k)_{k\in \mathbb{N}} \]
	wobei
		\[ c_k := \sum_{j=0}^{k}a_jb_{k-j}. \]
	\end{Definition}
	Insbesondere gilt damit
		\begin{gather*}
		\forall j,k\in \mathbb{N}: e_j \odot e_k = e_{j+k}
		\Rightarrow \forall k\in \mathbb{N}:
			\begin{cases}
				e_0 \odot e_k = e_k\\
				e_1^k = \underset{k \text{ mal}}{\underbrace{e_1 \odot \cdots \odot e_1}} = e_k
			\end{cases}
		\end{gather*}
	Mit $ 1:= e_0,\ t:= e_1 $ und $ t^0 := 1 $, wie üblich, liefert dies:
		\[ \sum_{k=0}^{n}t^ka_k = \sum_{k\in \mathbb{N}}e_ka_k \in [(e_k)_{k\in N}]\subset K^\mathbb{N} \]
\subsection{Definition}\index{Polynom!-algebra}\index{Polynom!Grad}\index{Polynom!normiertes}
		\begin{Definition}[Polynomalgebra]
			\[ K[t] := ([(e_k)_{k\in \mathbb{N}}],\odot) ,\]
	mit dem Cauchyprodukt $ \odot $, ist die \emph{Polynomalgebra} über dem Körper $ K $; die Elemente von $ K[t] $,
		\[ p(t) = \sum_{k=0}^{n}t^ka_k = \sum_{k\in\mathbb{N}}e_ka_k, \]
	heißen \emph{Polynome in der Variablen} $ t:= e_1 $.
	Der \emph{Grad} eines Polynoms ist
		\[  \deg\sum_{k=0}^{n}t^ka_k := \max \{k\in \mathbb{N}\mid a_k \neq 0\}  \quad \left( \text{bzw. } \deg 0 := -\infty \right) \]
	Ist (der "`höchste"' Koeffizient) $ a_n = 1 $ für $ \deg p(t) = n $, so heißt das Polynom $ p(t) $ \emph{normiert}.
		\end{Definition}
\paragraph{Notation}
	Mit $t^k = e_{k}$, also $ K[t] = [(e_k)_{k\in N}] $
	wird das Cauchyprodukt auf $ K[t] $ eine "`normale"' Multiplikation, gefolgt von einer Sortierung nach den Potenzen der Variablen $ t $. Wir werden das $ \odot $ daher oft unterdrücken, und z.B. $ p(t)q(t) $ schreiben, anstelle von $ p(t) \odot q(t) $.
\paragraph{Bemerkung (Koeffizientenvergleich)}
	Mit dieser Definition von "`Polynom"' gilt
		\begin{align*}
			p(t)=\sum_{k=0}^{n}t^ka_k = 0
			\Rightarrow \forall k\in \mathbb{N}: a_k = 0,
		\end{align*}
	da $ (t^k)_{k\in \mathbb{N}} = (e_k)_{k\in \mathbb{N}}$ linear unabhängig ist.
	Koeffizientenvergleich funktioniert!
\paragraph{Bemerkung}
	Die Polynomalgebra $ K[t] $ über $ K $ ist eine assoziative und kommutative $ K $-Algebra, weiters ist $ K[t] $ unitär mit Einselement $ 1=e_0 $.
\subsection{Definition}\index{Algebra}
	\begin{Definition}[Algebra]
		Eine $ K $-Algebra ist ein $ K $-VR mit einer \emph{bilinearen Abbildung},
		\[ \odot: V\times V \to V,\ (v,w)\mapsto v\odot w, \]
	d.h. es gilt
		\begin{enumerate}[(i)]
			\item $ \forall w\in V:\ V\ni v\mapsto v\odot w\in V $ ist linear;
			\item $ \forall v\in V: V\ni w\mapsto v\odot w\in V $ ist linear.
		\end{enumerate}
	
	Eine $ K $-Algebra heißt
		\begin{itemize}
			\item unitär (mit Einselement 1), falls  \hfill$ \exists 1\in V\forall v\in V: 1\odot v = v\odot 1 = v; $
			\item assoziativ, falls \hfill$ \forall u,v,w\in V: (u\odot v)\odot w = u\odot (v\odot w); $
			\item kommutativ, falls \hfill$ \forall v,w,\in V: v\odot w = w\odot v $
		\end{itemize}
	\end{Definition}
\paragraph{Beispiel}
	$ \End(V) $ ist (mit Komposition) eine unitäre assoziative Algebra.
\paragraph{Bemerkung}
	In jeder Algebra $ (V,\odot) $ gilt:
		\[ \forall v\in V: 0\odot v = v\odot 0 = 0 \]
	da z.B. für $ v\in V $ gilt
		\[ v\odot 0 = v\odot (0+0) = v\odot 0 + v\odot 0 \ \Rightarrow\  0=v\odot 0\]
	Ist $ (V,\odot) $ unitär, so folgt $ [1]\subset V $ wegen $ 1\odot 1 = 1 $
		\[ ([1], +\mid_{[1]\times [1]},\odot\mid_{[1]\times [1]} ) \cong K \]
	vermöge $ K\ni x \mapsto 1 \cdot x\in [1] $ (siehe Aufgabe 5).
\subsection{Definition}\index{Algebra!-Homomorphismus}
	\begin{Definition}[Algebra-Homomorphismus]
		Ein \emph{Algebra-Homomorphismus} zwischen $ K $-Algebren $ (V,\odot) $ und $ (W,*) $ ist eine lineare Abbildung $ \psi\in \hom(V,W) $, für die gilt:
		\[ \forall v,v' \in V: \psi(v\odot v')=\psi(v)*\psi(v') \]
	\end{Definition}
\paragraph{Bemerkung}
	$ \hom(V,W) $ wird oft auch für den (Vektor-)Raum der Algebra-Homomorphismen verwendet. In dieser LVA bedeutet $ \hom(V,W) $ immer VR-Homomorphismen, bei allen "`anderen"' Homomorphismen wird extra erwähnt, was gemeint ist.

%VO2-2016-03-03

\subsection{Einsetzungssatz \& Definitionen}
	\begin{Satz}[Einsetzungssatz]\index{Einsetzungshomomorphismus}\index{Polynom!funktion}
		Seien $ (V,\odot) $ eine unitäre assoziative Algebra und $ v\in V $. Dann ist
			\[ \psi_v: K[t]\to V,\ \sum_{k=0}^{n}t^ka_k = p(t)\mapsto \psi_v(p(t)) := \sum_{k=0}^{n}v^ka_k \]
		-- wobei $ v^0 = 1 $ sinnvoll ist, da die Algebra unitär ist -- ein Algebra-Homomorphismus; $ \psi_v $ heißt \emph{Einsetzungshomomorphismus}. 
			\[ p:V\to V,\ v\mapsto p(v) := \psi_v(p(t)) \]
		heißt die zu $ p(t)\in K[t] $ gehörige \emph{Polynomfunktion} auf $ V $.
	\end{Satz}
\paragraph{Bemerkung}
	Wie üblich: $ v^k := \underset{k-\text{mal}}{\underbrace{v\odot\cdots \odot v}} $ und $ v^0 := 1 $.
\paragraph{Beweis}
	\begin{enumerate}
		\item $ \psi_v $ ist linear:
			\begin{itemize}
				\item für $ p(t) = \sum_{k\in\mathbb{N}} t^ka_k $ und $ a\in K $ gilt:
					\[ \psi_v(p(t)a) = \psi_v(\sum_{k\in\mathbb{N}} t^ka_ka) = \sum_{k\in\mathbb{N}} v^ka_ka = \psi_v(p(t))a; \]
				\item für $ p(t) = \sum_{k\in\mathbb{N}} t^ka_k $ und $ q(t) = \sum_{k\in\mathbb{N}} t^k b_k $ gilt:
					\[ \psi_v(p(t)+q(t)) = \psi_v(\sum_{k\in\mathbb{N}}t^k(a_k+b_k)) = \sum_{k\in\mathbb{N}} v^k(a_k+b_k) = \psi_v(p(t))+\psi_v(q(t)) \]
			\end{itemize}
		\item $ \psi_v $ ist verträglich mit der Multiplikation:
		
			Für die Vektoren der Basis $ (t^k)_{k\in\mathbb{N}} $ von $ K[t] $ gilt, da $ (V,\odot) $ assoziativ ist,
				\[ \psi_v(t^mt^n) = \psi_v(t^{m+n}) = v^{m+n} = v^m\odot v^n = \psi_v(t^m)\odot \psi_v(t^n). \]
			Da aber $ \psi_v $ linear und die Multiplikation in $ K[t] $ und in $ (V,\odot) $ bilinear sind, folgt die Behauptung.
	\end{enumerate}
\paragraph{Bemerkung (Fortsetzungssatz für bilineare Abbildungen)}
	Im Beweis haben wir verwendet: Die Abbildungen
		\[ K[t]\times K[t]\to V,\ (p(t),q(t))\mapsto
			\begin{cases}
			\psi_v(p(t)q(t))& \text{ (Cauchyprodukt)}\\
			\psi_v(p(t))\odot \psi_v(q(t)) & \text{(Produkt in $ (V,\odot) $)}
			\end{cases} \]
	sind bilinear (da $ \psi_v $ linear ist), sind also gleich, sobald sie auf einer Basis übereinstimmen.
	Dies ist die Eindeutigkeit eines Fortsetzungssatzes für bilineare Abbildungen:
	
	Sind $ V,W\ K$-VR, $ (b_i)_{i\in I} $ eine Basis von $ V $ und $ (\beta_{ij})_{i,j\in I} $ eine Familie in $ W $, so gibt es eine eindeutige bilineare Abbildung
		\[ \beta: V\times V\to W \]
	mit
		\[ \forall i,j\in I: \beta(b_i,b_j) = \beta_{ij} \]
	Dieser Fortsetzungssatz folgt direkt aus dem Fortsetzungssatz für lineare Abbildungen, da
		\[ \{\beta:V\times V\to W \text{ bilinear}\} \cong \hom(V,\hom(V,W))\]
	vermittels des Isomorphismus
		\[ \beta \mapsto \big(v\mapsto\underset{\in \hom(V,W)}{\underbrace{\beta(v,.)}}\big), \]
	d.h. durch Nacheinandereinsetzen der Argumente.
\paragraph{Bemerkung}
	Die Abbildung eines Polynoms auf seine Polynomfunktion auf dem Körper,
		\[ K[t]\ni p(t)\mapsto (x\mapsto p(x))=\psi_x(p(t))\in K^K \]
	ist für $ \Char K\neq 0 $ nicht injektiv, das heißt: Koeffizientenvergleich kann nur funktionieren, wenn $ \Char K = 0 $
\paragraph{Beispiel \& Bemerkung}
	Ist $ V\ K $-VR, so ist $ \End(V) $ eine $ K $-Algebra (mit Komposition $ \circ $). Man erhält also für $ f\in \End(V) $ einen Einsetzungshomomorphismus
		\[ \psi_f: K[t]\to \End(V),\ p(t) \mapsto \psi_f(p(t)) = p(f); \]
	und für jedes Polynom $ p(t)\in K[t] $ eine zugehörige Polynomfunktion
		\[ p: \End(V)\to\End(V),\ f\mapsto \psi_f(p(t))= p(f). \]
	Dieses Beispiel ist der Schlüssel zum Satz von Cayley-Hamilton (im nächsten Abschnitt).
\subsection{Lemma}
	\begin{Lemma}
		Für Polynome $ p(t), q(t)\in K[t] $ gilt:
			\begin{itemize}
				\item $ \deg p(t)\odot q(t) = \deg p(t)+\deg q(t) $,
				\item $ \deg p(t)+q(t) \leq \max\{\deg p(t), \deg q(t)\} $.
			\end{itemize}
	\end{Lemma}
\paragraph{Beweis}
	Für $ p(t) = \sum_{k\in\mathbb{N}}t^ka_k $ und $ q(t) = \sum_{k\in\mathbb{N}}t^kb_k $ ist
		\[ p(t)\odot q(t) = \sum_{k\in\mathbb{N}}t^kc_k \text{ mit } c_k = \sum_{j=0}^{k}a_jb_{k-j} \]
	Gilt nun $ \deg p(t) = n $ und $ \deg q(t) = m $, d.h.
		\[ a_n,b_m \neq 0 \land \forall k>n, k'>m:a_k = b_{k'}=0 \] 
	so folgt
		\[ \left.
		\begin{aligned}
		\forall k>m+n : c_k = 0\ \\
		        c_{m+n} = a_nb_m\ \\
		\end{aligned}
		 \right\}
		\Rightarrow \deg p(t)\odot q(t) = m+n \]
	Gilt andererseits $ \deg p(t) = -\infty $ oder $ \deg q(t) = -\infty $, also $ p(t) = 0 \lor q(t) = 0 $,
	so folgt
		\[ p(t)\odot q(t) = 0 \Rightarrow \deg p(t)\odot q(t) = -\infty. \]
	Die zweite Behauptung ist offensichtlich wahr.
